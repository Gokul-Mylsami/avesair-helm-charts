# Frontend configuration

external-secrets:
  enabled: true

frontend:
  replicaCount: 1
  containerName: frontend
  image:
    repository: gokulmsfag/finaltask-frontend
    tag: latest
    pullPolicy: Always
  resources:
    requests:
      cpu: "300m"
      memory: "64Mi"
    limits:
      cpu: "500m"
      memory: "128Mi"
  env:
    - name: BACKEND_API
      valueFrom:
        configMapKeyRef:
          name: application-config
          key: BACKEND_API
  port: 80

  service:
    type: ClusterIP
    port: 80
    targetPort: 80
    protocol: TCP

# backend configuration

backend:
  replicas: 1
  containerName: backend
  image:
    repository: gokulmsfag/finaltask-backend
    tag: latest
    pullPolicy: Always
  resources:
    requests:
      memory: 256Mi
      cpu: 500m
    limits:
      memory: 512Mi
      cpu: 1
  env:
    - name: PORT
      valueFrom:
        configMapKeyRef:
          name: application-config
          key: PORT
    - name: NODE_ENV
      valueFrom:
        configMapKeyRef:
          name: application-config
          key: NODE_ENV
    - name: MONGO_URL
      valueFrom:
        secretKeyRef:
          name: application-secrets
          key: MONGO_URL
    - name: JWT_SECRET
      valueFrom:
        secretKeyRef:
          name: application-secrets
          key: JWT_SECRET
    - name: JWT_EXPIRES_IN
      value: 1d
    - name: EMAIL_SERVICE
      value: gmail
    - name: EMAIL_USERNAME
      valueFrom:
        secretKeyRef:
          name: application-secrets
          key: EMAIL_USERNAME
    - name: EMAIL_PASSWORD
      valueFrom:
        secretKeyRef:
          name: application-secrets
          key: EMAIL_PASSWORD
    - name: FRONTEND_URL
      value: frontend.gokulmylsami.me
  port: 
    - containerPort: 8000
  
  service: 
    type: ClusterIP
    port: 8000
    targetPort: 8000
    protocol: TCP

# Alertmanager configuration
alertmanager:
  deployment:
    replicas: 1
    containerName: alertmanager
    image:
      repository: quay.io/prometheus/alertmanager
      tag: v0.23.0
    args:
      - "--config.file=/etc/alertmanager/config/alertmanager.yaml"
      - "--storage.path=/data"
    env:
      - name: SLACK_URL
        valueFrom:
        secretKeyRef:
          name: application-secrets
          key: SLACK_URL
    resources:
      limits:
        cpu: "100m"
        memory: 128Mi
    volumeMounts:
      - name: config-volume
        mountPath: /etc/alertmanager/config
      - name: storage-volume
        mountPath: /data
    volumes:
      - name: config-volume
        configMap:
          name: alertmanager-config
      - name: storage-volume
        emptyDir: {}

  config:
    alertmanagerYaml:
      global:
        resolve_timeout: 5m
      route:
        group_by: ["alertname"]
        group_wait: 10s
        group_interval: 10s
        repeat_interval: 1h
        receiver: "slack-notifications"
      receivers:
        - name: "slack-notifications"
          slack_configs:
            - channel: "#prometheus-alerts"
              api_url: "https://hooks.slack.com/services/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"
              send_resolved: true

  service:
    ports:
      name: web
      port: 9093
      targetPort: 9093

# grafana
grafana:
  replica: 1
  containerName: grafana
  image:
    repository: grafana/grafana
    tag: latest
    pullPolicy: Always
  resources:
    limits:
      memory: 128Mi
      cpu: 100m
  ports: 
    - containerPort: 3000
  
  service: 
    type: ClusterIP
    port: 3000
    targetPort: 3000
    protocol: TCP

hpa: 
  minReplicas: 1
  maxReplicas: 4
  metrics: 
    name: cpu
    target: 
      averageUtilization: 70
      type: Utilization
    type: Resource
  scaleTargetRef: 
    apiVersion: apps/v1
    kind: Deployment
    name: backend-deployment

mongoJob:
  completions: 1
  containerName: mongodb-replica-set-config
  image:
    repository: gokulmsfag/mongo-job
    tag: latest
    pullPolicy: Always
  command: 
    - "/bin/sh"
    - "-c"
    - "./script.sh mongodb-0.mongodb-service.default.svc.cluster.local mongodb-1.mongodb-service.default.svc.cluster.local mongodb-2.mongodb-service.default.svc.cluster.local"
  restartPolicy: Never

configMap:
  PORT: "8000"
  NODE_ENV: production
  JWT_EXPIRE: 1d
  EMAIL_SERVICE: gmail
  FRONTEND_URL: frontend-service.default
  BACKEND_API: backend-service.default:8000

storageClass:
  provisioner: efs.csi.aws.com

stressJob:
  completions: 1
  containerName: stress-job
  image: 
    repository: gokulmsfag/testing-job
    tag: 1
    pullPolicy: Always
  command: ["node","tester.js"]
  restartPolicy: Never
  initContainers:
    name: wait-for-backend
    image: busybox
    command: ['sh', '-c', 'until nslookup backend-service.default; do echo waiting for backend; sleep 5; done;']

kubeStateMetrics:
  name: kube-state-metrics
  clusterRole:
    rules:
      - apiGroups: ["*"]
        resources: ["*"]
        verbs: ["list","watch"]

  clusterRoleBinding:
    subjects:
      - kind: ServiceAccount
        name: kube-state-metrics
        namespace: default
    roleRef:
      kind: ClusterRole
      name: kube-state-metrics
      apiGroup: rbac.authorization.k8s.io
  
  deployment: 
    replicas: 1
    containerName: kube-state-metrics
    image:
      repository: quay.io/coreos/kube-state-metrics
      tag: latest
    resources:
      limits:
        memory: "128Mi"
        cpu: "100m"
    ports:
      - containerPort: 8080

  service:
    type: ClusterIP
    ports: 
      - port: 8080
        targetPort: 8080
        protocol: TCP

mongodb: 
  replicas: 3
  containerName: mongodb
  image: 
    repository: mongo
    tag: 4.0.8
  args: 
    - "--replSet"
    - "rs0"
    - --bind_ip_all
  ports:
    - name: mongodb
      containerPort: 27017
  volumeMounts:
    - name: data
      mountPath: /data/db
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteMany"]
        storageClassName: aws-efs-sc
        resources:
          requests:
            storage: 1Gi  
  service:
    type: ClusterIP
    clusterIP: None
    ports: 
      - port: 27017
        targetPort: 27017
        protocol: TCP
        name: mongo-db

networkPolicy:
  policyTypeForBackend: 
    - Ingress

nodeExporter:
  namespace: monitoring
  hostNetwork: true
  containerName: prometheus-node-exporter
  image: 
    repository: quay.io/prometheus/node-exporter
    tag: v1.2.2
  ports:
    - name: http
      containerPort: 9100
  resources:
    limits:
      memory: "128Mi"

  service: 
    type: NodePort
    ports:
      - name: http
        port: 9100
        targetPort: 9100
        nodePort: 30910

  clusterRole:
    rules: 
      - apiGroups: [""]
        resources: ["nodes","pods"]
        verbs: ["get","list","watch"]

  clusterRoleBinding:
    subjects:
      - kind: ServiceAccount
        name: prometheus-node-exporter
        namespace: monitoring
    roleRef: 
      kind: ClusterRole
      name: node-exporter
      apiGroup: rbac.authorization.k8s.io

pdb:
  backend: 
    name: backend-pdb
    minAvailable: 2
  frontend:
    name: frontend-pdb
    minAvailable: 1
  mongo:
    name: mongo-pdb
    minAvailable: 1

prometheus:
  replicas: 1
  containerName: prometheus
  image:
    repository: prom/prometheus
    tag: latest
  args:
    - "--config.file=/etc/prometheus/prometheus.yml"
  ports:
    - containerPort: 9090
  resources:
    limits: 
      memory: "128Mi"
      cpu: "250m"
  volumes: 
    prometheusConfigName: prometheus-config
    mountPath: /etc/prometheus

  service: 
    port: 9090
    type: ClusterIP
    ports:
      - port: 9090
        targetPort: 9090
        protocol: TCP   
  configMap:
    prometheus: 
      global:
        scrape_interval: 15s
      alerting:
        alertmanagers:
          - static_configs:
              - targets:
                  - alertmanager:9093
      rule_files:
        - alert.rules.yml

      scrape_configs:
        - job_name: 'prometheus'
          static_configs:
            - targets: ['localhost:9090']
        - job_name: 'backend'
          static_configs:
            - targets: ['backend-service.default:8000']
        - job_name: 'kubernetes-state-metrics'
          static_configs:
            - targets: ['kube-state-metrics.default:8080']
        - job_name: 'ec2-instances'
          ec2_sd_configs:
            - region: 'us-east-1'
          relabel_configs:
            - source_labels: [__meta_ec2_public_ip]
              target_label: __address__
              replacement: '${1}:30910'

    alertRules: 
      groups:
        - name: alert.rules
          rules:
            - alert: BackendDown
              expr: up{job="backend"} == 0
              for: 1m
              labels:
                severity: critical
              annotations:
                summary: "Backend is down"
                description: "Backend is down for more than 1 minute"
            - alert: HighLatency
              expr: histogram_quantile(0.95, sum(rate(http_request_duration_bucket{job="backend"}[5m])) by (le)) > 0.5
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: "High latency"
                description: "High latency for more than 1 minute"
            - alert: HighThroughput
              expr: sum(rate(http_request_duration_count{job="backend"}[5m])) by (le) > 100
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: "High throughput"
                description: "High throughput for more than 1 minute"
            - alert: HighErrorRate
              expr: sum(rate(http_request_duration_count{job="backend", status=~"5.."}[5m])) by (le) / sum(rate(http_request_duration_count{job="backend"}[5m])) by (le) > 0.01
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: "High error rate"
                description: "High error rate for more than 1 minute"
            - alert: HighCPUUsage
              expr: sum(rate(container_cpu_usage_seconds_total{namespace="default", container="backend"}[5m])) by (pod_name) / sum(container_spec_cpu_quota{namespace="default", container="backend"}) by (pod_name) * 100 > 80
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: "High CPU usage"
                description: "High CPU usage for more than 1 minute"
            - alert: HighMemoryUsage
              expr: sum(container_memory_usage_bytes{namespace="default", container="backend"}) by (pod_name) / sum(container_spec_memory_limit_bytes{namespace="default", container="backend"}) by (pod_name) * 100 > 80
              for: 1m

pv: 
  efsId1: fs-0b160979a18957eec
  efsId2: fs-0fc3deefe7670967a
  efsId3: fs-06f24b7d93b73a626
  volumeMode: Filesystem
  capacity: 
    storage: 2Gi
  accessModes:
    - "ReadWriteMany"
  csi:
    driver: efs.csi.aws.com

secretStore:
  namespace: external-secrets

  provider:
    aws:
      service: SecretsManager
      region: us-east-1
      auth:
        jwt:
          serviceAccountRef:
            name: external-secrets-irsa

externalSecret: 
  refreshInterval: 10m
  secretStoreKind: SecretStore
  data: 
    - secretKey: MONGO_URL
      remoteRef:
        key: eksSecretKeys
        property: MONGO_URL
    - secretKey: JWT_SECRET
      remoteRef:
        key: eksSecretKeys
        property: JWT_SECRET
    - secretKey: EMAIL_USERNAME
      remoteRef:
        key: eksSecretKeys
        property: EMAIL_USERNAME
    - secretKey: EMAIL_PASSWORD
      remoteRef:
        key: eksSecretKeys
        property: EMAIL_PASSWORD
    - secretKey: SLACK_URL
      remoteRef:
        key: eksSecretKeys
        property: SLACK_URL

argocd:
  namespace: argocd